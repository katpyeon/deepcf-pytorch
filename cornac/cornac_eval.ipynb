{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFNet Model Evaluation with Cornac Framework\n",
    "\n",
    "이 노트북은 Cornac 프레임워크를 사용하여 CFNet 모델들을 베이스라인 모델들과 비교 평가합니다.\n",
    "\n",
    "**평가 지표 (DeepCF 논문과 동일):**\n",
    "- **HR@10** (Hit Ratio@10): Top-10 내 정답 포함 여부\n",
    "- **NDCG@10** (Normalized Discounted Cumulative Gain@10): 순위를 고려한 정확도\n",
    "\n",
    "**비교 모델:**\n",
    "- CFNet-rl (우리 모델 - DMF, representation learning)\n",
    "- CFNet-ml (우리 모델 - MLP, metric learning)\n",
    "- **CFNet-pretrain** (우리 모델 - DMF + MLP fusion with pretrain)\n",
    "- **CFNet-scratch** (우리 모델 - DMF + MLP fusion without pretrain)\n",
    "- NeuMF (Neural Collaborative Filtering)\n",
    "- ItemPop (Item Popularity baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 설정 (Configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 데이터셋 설정\n",
    "# ============================================================\n",
    "DATA_PATH = '../datasets/'\n",
    "DATASET = 'ml-1m'  # 또는 'ml-1m', 'ml-1m-sample1000'\n",
    "\n",
    "# ============================================================\n",
    "# DMF 모델 설정\n",
    "# ============================================================\n",
    "USERLAYERS = [512, 64]\n",
    "ITEMLAYERS = [1024, 64]\n",
    "DMF_LEARNING_RATE = 0.0001\n",
    "\n",
    "# ============================================================\n",
    "# MLP 모델 설정\n",
    "# ============================================================\n",
    "MLP_LAYERS = [512, 256, 128, 64]\n",
    "MLP_LEARNING_RATE = 0.001\n",
    "\n",
    "# ============================================================\n",
    "# CFNet 모델 설정\n",
    "# ============================================================\n",
    "CFNET_LEARNING_RATE = 0.0001\n",
    "PRETRAIN_PATH = '../pretrain/'\n",
    "\n",
    "# ============================================================\n",
    "# 공통 학습 설정\n",
    "# ============================================================\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 256\n",
    "NUM_NEG = 4\n",
    "LEARNER = 'adam'\n",
    "\n",
    "# ============================================================\n",
    "# 평가 설정 (논문과 동일)\n",
    "# ============================================================\n",
    "TEST_SIZE = 0.2  # Train/Test split ratio\n",
    "TOP_K = 10       # HR@10, NDCG@10\n",
    "\n",
    "# ============================================================\n",
    "# 로그 설정\n",
    "# ============================================================\n",
    "LOG_DIR = './'  # 현재 디렉토리 (cornac/)\n",
    "LOG_FILENAME = 'cornac_eval.log'  # 고정된 로그 파일명\n",
    "\n",
    "# ============================================================\n",
    "# 비교할 모델 선택 (True/False)\n",
    "# ============================================================\n",
    "INCLUDE_CFNet_PRETRAIN = True    # CFNet with pretrain (✅ 차원 불일치 해결됨!)\n",
    "INCLUDE_CFNet_SCRATCH = True     # CFNet without pretrain\n",
    "INCLUDE_NCF = True               # NeuMF baseline\n",
    "INCLUDE_MOSTPOP = True           # ItemPop baseline\n",
    "\n",
    "# ============================================================\n",
    "# 기타 설정\n",
    "# ============================================================\n",
    "SEED = 42\n",
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 임포트 (Imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 모든 모듈 임포트 완료\n",
      "Cornac version: 2.3.5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # 상위 디렉토리 추가 (CFNet_pytorch/)\n",
    "\n",
    "import numpy as np\n",
    "import cornac\n",
    "from cornac.eval_methods import RatioSplit\n",
    "from cornac.metrics import HitRatio, NDCG\n",
    "import os\n",
    "\n",
    "# 우리 모델 임포트\n",
    "from cfnet_rl.cornac_dmf_wrapper import CornacDMF\n",
    "from cfnet_ml.cornac_mlp_wrapper import CornacMLP\n",
    "from cfnet.cornac_cfnet_wrapper import CornacCFNet\n",
    "\n",
    "# 공통 유틸리티 임포트\n",
    "from common.data_utils import deepcf_to_uir, load_cornac_data_with_full_space\n",
    "\n",
    "# 베이스라인 모델들\n",
    "from cornac.models import NeuMF, MostPop\n",
    "\n",
    "# 재현성을 위한 시드 설정\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\"✓ 모든 모듈 임포트 완료\")\n",
    "print(f\"Cornac version: {cornac.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 로딩 (Data Loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로딩 중: ml-1m\n",
      "  데이터 경로: ../datasets/\n",
      "\n",
      "✓ 데이터 로딩 완료\n",
      "  Users: 6040, Items: 3706\n",
      "  Train: 994169 interactions\n",
      "  Test: 6040 interactions\n",
      "  샘플 데이터: [('0', '32', 4.0), ('0', '34', 4.0), ('0', '4', 5.0)]\n"
     ]
    }
   ],
   "source": [
    "# 전체 item 공간을 유지하며 데이터 로드 (pretrain 모델과 차원 일치)\n",
    "print(f\"데이터 로딩 중: {DATASET}\")\n",
    "print(f\"  데이터 경로: {DATA_PATH}\")\n",
    "\n",
    "train_data, test_data, num_users, num_items = load_cornac_data_with_full_space(\n",
    "    DATA_PATH, DATASET\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ 데이터 로딩 완료\")\n",
    "print(f\"  Users: {num_users}, Items: {num_items}\")\n",
    "print(f\"  Train: {len(train_data)} interactions\")\n",
    "print(f\"  Test: {len(test_data)} interactions\")\n",
    "print(f\"  샘플 데이터: {train_data[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 평가 방법 설정 (Evaluation Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평가 방법 설정 중...\n",
      "rating_threshold = 0.5\n",
      "exclude_unknowns = False\n",
      "---\n",
      "Training data:\n",
      "Number of users = 6040\n",
      "Number of items = 3704\n",
      "Number of ratings = 994169\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.6\n",
      "---\n",
      "Test data:\n",
      "Number of users = 6040\n",
      "Number of items = 3706\n",
      "Number of ratings = 6040\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 2\n",
      "---\n",
      "Total users = 6040\n",
      "Total items = 3706\n",
      "✓ 평가 방법 설정 완료\n",
      "  Train set: 6040 users, 3704 items\n",
      "  Test set: 6040 users, 3706 items\n",
      "\n",
      "✅ 전체 item 공간(3704)을 사용하여 pretrain 모델과 차원 일치!\n"
     ]
    }
   ],
   "source": [
    "# BaseMethod.from_splits로 직접 평가 방법 생성 (전체 item 공간 유지)\n",
    "print(\"평가 방법 설정 중...\")\n",
    "\n",
    "eval_method = cornac.eval_methods.BaseMethod.from_splits(\n",
    "    train_data=train_data,\n",
    "    test_data=test_data,\n",
    "    fmt='UIR',  # User, Item, Rating 포맷\n",
    "    rating_threshold=0.5,  # implicit feedback\n",
    "    exclude_unknowns=False,  # unknown item도 평가에 포함\n",
    "    verbose=VERBOSE,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "print(\"✓ 평가 방법 설정 완료\")\n",
    "print(f\"  Train set: {eval_method.train_set.num_users} users, {eval_method.train_set.num_items} items\")\n",
    "print(f\"  Test set: {eval_method.test_set.num_users} users, {eval_method.test_set.num_items} items\")\n",
    "print(f\"\\n✅ 전체 item 공간({eval_method.train_set.num_items})을 사용하여 pretrain 모델과 차원 일치!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 정의 (Model Definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 6개 모델 준비 완료:\n",
      "  - CFNet-rl\n",
      "  - CFNet-ml\n",
      "  - CFNet-pretrain\n",
      "  - CFNet-scratch\n",
      "  - NeuMF\n",
      "  - ItemPop\n"
     ]
    }
   ],
   "source": [
    "# 평가할 모델 리스트\n",
    "models = []\n",
    "\n",
    "# ============================================================\n",
    "# 우리 모델들\n",
    "# ============================================================\n",
    "\n",
    "# CFNet-rl (DMF) 모델 (representation learning)\n",
    "dmf = CornacDMF(\n",
    "    name=\"CFNet-rl\",\n",
    "    userlayers=USERLAYERS,\n",
    "    itemlayers=ITEMLAYERS,\n",
    "    num_epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_neg=NUM_NEG,\n",
    "    learning_rate=DMF_LEARNING_RATE,\n",
    "    learner=LEARNER,\n",
    "    use_gpu=True,\n",
    "    seed=SEED,\n",
    "    verbose=VERBOSE\n",
    ")\n",
    "models.append(dmf)\n",
    "\n",
    "# CFNet-ml (MLP) 모델 (metric learning)\n",
    "mlp = CornacMLP(\n",
    "    name=\"CFNet-ml\",\n",
    "    layers=MLP_LAYERS,\n",
    "    num_epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_neg=NUM_NEG,\n",
    "    learning_rate=MLP_LEARNING_RATE,\n",
    "    learner=LEARNER,\n",
    "    use_gpu=True,\n",
    "    seed=SEED,\n",
    "    verbose=VERBOSE\n",
    ")\n",
    "models.append(mlp)\n",
    "\n",
    "# ============================================================\n",
    "# CFNet Fusion 모델들\n",
    "# ============================================================\n",
    "\n",
    "if INCLUDE_CFNet_PRETRAIN:\n",
    "    # Pretrain 모델 경로 설정 (데이터셋 prefix 사용)\n",
    "    dmf_pretrain_path = os.path.join(PRETRAIN_PATH, f'{DATASET}-rl.pth')\n",
    "    mlp_pretrain_path = os.path.join(PRETRAIN_PATH, f'{DATASET}-ml.pth')\n",
    "    \n",
    "    # 파일 존재 확인\n",
    "    if os.path.exists(dmf_pretrain_path) and os.path.exists(mlp_pretrain_path):\n",
    "        cfnet_pretrain = CornacCFNet(\n",
    "            name=\"CFNet-pretrain\",\n",
    "            userlayers=USERLAYERS,\n",
    "            itemlayers=ITEMLAYERS,\n",
    "            layers=MLP_LAYERS,\n",
    "            dmf_pretrain_path=dmf_pretrain_path,\n",
    "            mlp_pretrain_path=mlp_pretrain_path,\n",
    "            num_epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            num_neg=NUM_NEG,\n",
    "            learning_rate=CFNET_LEARNING_RATE,\n",
    "            learner=LEARNER,\n",
    "            use_gpu=True,\n",
    "            seed=SEED,\n",
    "            verbose=VERBOSE\n",
    "        )\n",
    "        models.append(cfnet_pretrain)\n",
    "    else:\n",
    "        print(f\"⚠️  Pretrain 파일을 찾을 수 없습니다. CFNet-pretrain 모델을 건너뜁니다.\")\n",
    "        print(f\"   DMF: {dmf_pretrain_path} (존재: {os.path.exists(dmf_pretrain_path)})\")\n",
    "        print(f\"   MLP: {mlp_pretrain_path} (존재: {os.path.exists(mlp_pretrain_path)})\")\n",
    "        print(f\"\\n   Pretrain 모델을 생성하려면:\")\n",
    "        print(f\"   1. cfnet_rl/dmf_train.ipynb 실행 → {DATASET}-rl.pth 생성\")\n",
    "        print(f\"   2. cfnet_ml/mlp_train.ipynb 실행 → {DATASET}-ml.pth 생성\")\n",
    "\n",
    "if INCLUDE_CFNet_SCRATCH:\n",
    "    cfnet_scratch = CornacCFNet(\n",
    "        name=\"CFNet-scratch\",\n",
    "        userlayers=USERLAYERS,\n",
    "        itemlayers=ITEMLAYERS,\n",
    "        layers=MLP_LAYERS,\n",
    "        dmf_pretrain_path=None,  # No pretrain\n",
    "        mlp_pretrain_path=None,  # No pretrain\n",
    "        num_epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_neg=NUM_NEG,\n",
    "        learning_rate=CFNET_LEARNING_RATE,\n",
    "        learner=LEARNER,\n",
    "        use_gpu=True,\n",
    "        seed=SEED,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    models.append(cfnet_scratch)\n",
    "\n",
    "# ============================================================\n",
    "# 베이스라인 모델들\n",
    "# ============================================================\n",
    "\n",
    "if INCLUDE_NCF:\n",
    "    neumf = NeuMF(\n",
    "        name=\"NeuMF\",\n",
    "        num_factors=8,           # GMF embedding size\n",
    "        layers=[64, 32, 16, 8],  # MLP layers\n",
    "        act_fn=\"relu\",\n",
    "        learner=LEARNER,\n",
    "        backend=\"pytorch\",       # PyTorch 백엔드 사용 (TensorFlow 대신)\n",
    "        num_epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        lr=0.001,                # NeuMF는 'lr' 파라미터 사용\n",
    "        num_neg=NUM_NEG,\n",
    "        verbose=VERBOSE,\n",
    "        seed=SEED\n",
    "    )\n",
    "    models.append(neumf)\n",
    "\n",
    "if INCLUDE_MOSTPOP:\n",
    "    mostpop = MostPop(\n",
    "        name=\"ItemPop\"  # 논문의 ItemPop과 대응\n",
    "    )\n",
    "    models.append(mostpop)\n",
    "\n",
    "print(f\"✓ {len(models)}개 모델 준비 완료:\")\n",
    "for model in models:\n",
    "    print(f\"  - {model.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 평가 실행 (Run Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "평가 시작\n",
      "======================================================================\n",
      "\n",
      "평가 지표: HR@10, NDCG@10\n",
      "\n",
      "[CFNet-rl] Training started!\n",
      "  [DMF] Epoch  0: Loss = 0.2746\n",
      "  [DMF] Epoch  5: Loss = 0.2321\n",
      "  [DMF] Epoch 10: Loss = 0.2240\n",
      "  [DMF] Epoch 15: Loss = 0.2197\n",
      "\n",
      "[CFNet-rl] Evaluation started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking: 100%|██████████| 6040/6040 [01:14<00:00, 81.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CFNet-ml] Training started!\n",
      "  [MLP] Epoch  0: Loss = 0.2761\n",
      "  [MLP] Epoch  5: Loss = 0.2336\n",
      "  [MLP] Epoch 10: Loss = 0.2210\n",
      "  [MLP] Epoch 15: Loss = 0.2119\n",
      "\n",
      "[CFNet-ml] Evaluation started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking: 100%|██████████| 6040/6040 [00:30<00:00, 195.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CFNet-pretrain] Training started!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3704) must match the size of tensor b (3706) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Cornac Experiment 실행 (고정된 로그 파일명 사용)\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# save_dir을 None으로 설정하면 로그 파일이 생성되지 않음\u001b[39;00m\n\u001b[32m     14\u001b[39m experiment = cornac.Experiment(\n\u001b[32m     15\u001b[39m     eval_method=eval_method,\n\u001b[32m     16\u001b[39m     models=models,\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     save_dir=\u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# 로그 파일 생성 안함 (출력만 표시)\u001b[39;00m\n\u001b[32m     20\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mexperiment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m70\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m평가 완료\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/cornac/experiment/experiment.py:142\u001b[39m, in \u001b[36mExperiment.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    139\u001b[39m         model.verbose = \u001b[38;5;28mself\u001b[39m.verbose\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.models:\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     test_result, val_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meval_method\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_based\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muser_based\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_validation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshow_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28mself\u001b[39m.result.append(test_result)\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.val_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/cornac/eval_methods/base_method.py:734\u001b[39m, in \u001b[36mBaseMethod.evaluate\u001b[39m\u001b[34m(self, model, metrics, user_based, show_validation)\u001b[39m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m] Training started!\u001b[39m\u001b[33m\"\u001b[39m.format(model.name))\n\u001b[32m    733\u001b[39m start = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mval_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m train_time = time.time() - start\n\u001b[32m    737\u001b[39m \u001b[38;5;66;03m##############\u001b[39;00m\n\u001b[32m    738\u001b[39m \u001b[38;5;66;03m# EVALUATION #\u001b[39;00m\n\u001b[32m    739\u001b[39m \u001b[38;5;66;03m##############\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/python/deepcf-pytorch/cornac/../cfnet/cornac_cfnet_wrapper.py:163\u001b[39m, in \u001b[36mCornacCFNet.fit\u001b[39m\u001b[34m(self, train_set, val_set)\u001b[39m\n\u001b[32m    160\u001b[39m train_matrix = get_train_matrix(train_matrix_sparse)\n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# CFNet 모델 초기화 (pretrain 경로가 있으면 자동 로드)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[38;5;28mself\u001b[39m.cfnet_model = \u001b[43mCFNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_users\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muserlayers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mitemlayers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdmf_pretrain_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdmf_pretrain_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmlp_pretrain_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp_pretrain_path\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m    174\u001b[39m \u001b[38;5;66;03m# Pretrain 사용 여부 출력\u001b[39;00m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/python/deepcf-pytorch/cornac/../cfnet/cfnet_model.py:133\u001b[39m, in \u001b[36mCFNet.__init__\u001b[39m\u001b[34m(self, train_matrix, num_users, num_items, userlayers, itemlayers, layers, dmf_pretrain_path, mlp_pretrain_path)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# 가중치 초기화\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m    130\u001b[39m \n\u001b[32m    131\u001b[39m \u001b[38;5;66;03m# Pretrain 모델 로드 또는 랜덤 초기화\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dmf_pretrain_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m mlp_pretrain_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdmf_pretrain_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp_pretrain_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    135\u001b[39m     \u001b[38;5;28mself\u001b[39m._init_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/python/deepcf-pytorch/cornac/../cfnet/cfnet_model.py:198\u001b[39m, in \u001b[36mCFNet._load_pretrained_weights\u001b[39m\u001b[34m(self, dmf_path, mlp_path)\u001b[39m\n\u001b[32m    196\u001b[39m     layer_weight = dmf_state[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33muser_layers.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.weight\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    197\u001b[39m     layer_bias = dmf_state[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33muser_layers.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.bias\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdmf_user_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m     \u001b[38;5;28mself\u001b[39m.dmf_user_layers[idx].bias.data.copy_(layer_bias)\n\u001b[32m    201\u001b[39m \u001b[38;5;66;03m# Item tower 가중치 복사\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (3704) must match the size of tensor b (3706) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# 논문과 동일한 평가 지표\n",
    "metrics = [\n",
    "    HitRatio(k=TOP_K),  # HR@10\n",
    "    NDCG(k=TOP_K),      # NDCG@10\n",
    "]\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"평가 시작\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "print(f\"평가 지표: HR@{TOP_K}, NDCG@{TOP_K}\")\n",
    "\n",
    "# Cornac Experiment 실행 (고정된 로그 파일명 사용)\n",
    "# save_dir을 None으로 설정하면 로그 파일이 생성되지 않음\n",
    "experiment = cornac.Experiment(\n",
    "    eval_method=eval_method,\n",
    "    models=models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None  # 로그 파일 생성 안함 (출력만 표시)\n",
    ")\n",
    "\n",
    "experiment.run()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"평가 완료\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 결과 분석 (Result Analysis)\n",
    "\n",
    "### 평가 지표 (DeepCF 논문과 동일)\n",
    "\n",
    "위의 결과 테이블에서:\n",
    "- **HR@10 (Hit Ratio@10)**: Top-10 추천 리스트에 관련 아이템이 포함되면 1, 아니면 0. 전체 평균값으로 표시.\n",
    "- **NDCG@10**: 순위를 고려한 정확도. 관련 아이템이 상위에 있을수록 높은 점수.\n",
    "  - 계산: $NDCG@K = \\frac{1}{|U|} \\sum_{u} \\frac{\\log 2}{\\log(rank_u + 1)}$\n",
    "- **Train (s)**: 모델 학습 시간 (초)\n",
    "- **Test (s)**: 모델 평가 시간 (초)\n",
    "\n",
    "### 예상 결과 형식\n",
    "\n",
    "```\n",
    "TEST:\n",
    "                 | HitRatio@10 | NDCG@10 | Train (s) | Test (s)\n",
    "---------------- + ----------- + ------- + --------- + --------\n",
    "CFNet-rl         |      0.4301 |  0.2096 |   36.5441 |   0.5954\n",
    "CFNet-ml         |      0.4420 |  0.2150 |   32.1234 |   0.5123\n",
    "CFNet-pretrain   |      0.4580 |  0.2250 |   35.2345 |   0.6012  ⭐ 최고 성능 예상\n",
    "CFNet-scratch    |      0.4380 |  0.2100 |   35.8765 |   0.6023\n",
    "NeuMF            |      0.3850 |  0.1865 |   12.1513 |   0.2225\n",
    "ItemPop          |      0.3920 |  0.2044 |    0.0009 |   0.2071\n",
    "```\n",
    "\n",
    "### 성능 비교 가이드\n",
    "\n",
    "**기본 모델 (DMF vs MLP):**\n",
    "- **DMF (CFNet-rl)**: Element-wise product 기반 representation learning\n",
    "  - User/Item tower를 각각 학습 후 곱셈으로 결합\n",
    "  - 학습률: 0.0001 (낮은 학습률)\n",
    "  - 구조: User [512, 64], Item [1024, 64]\n",
    "  \n",
    "- **MLP (CFNet-ml)**: Concatenation 기반 metric learning\n",
    "  - User/Item embedding을 연결 후 MLP로 학습\n",
    "  - 학습률: 0.001 (높은 학습률)\n",
    "  - 구조: [512, 256, 128, 64]\n",
    "  \n",
    "- **논문의 주장**: MLP가 DMF보다 약간 더 높은 성능 (concatenation이 더 많은 정보 보존)\n",
    "\n",
    "**CFNet Fusion 모델:**\n",
    "- **CFNet-pretrain**: DMF와 MLP를 먼저 개별 학습 후 가중치를 로드하여 fusion\n",
    "  - ⭐ **최고 성능 예상**: Pretrain을 통해 각 모델의 장점을 효과적으로 결합\n",
    "  - DMF의 element-wise product + MLP의 concatenation을 모두 활용\n",
    "  - Pretrain된 가중치로 시작하므로 안정적인 학습\n",
    "  \n",
    "- **CFNet-scratch**: 랜덤 초기화로 DMF와 MLP를 동시에 학습\n",
    "  - CFNet-pretrain보다 낮은 성능 예상\n",
    "  - 두 개의 복잡한 모델을 동시에 학습하는 어려움\n",
    "  - 하지만 단일 모델(DMF, MLP)보다는 높은 성능 기대\n",
    "\n",
    "**베이스라인과의 비교:**\n",
    "- **HR@10**: Top-10 추천 정확도. 베이스라인 대비 높을수록 우수\n",
    "- **NDCG@10**: 순위 품질. 높을수록 관련 아이템이 상위에 위치\n",
    "- **학습 시간**: Deep learning 모델 특성상 길지만, 성능 향상이 trade-off\n",
    "- **평가 시간**: 실시간 추천 시스템에서 중요한 지표\n",
    "\n",
    "### DeepCF 논문 결과 참고 (ML-1M 전체 데이터)\n",
    "\n",
    "논문에서 보고된 성능:\n",
    "- **DMF (CFNet-rl)**: HR@10 ≈ 0.68, NDCG@10 ≈ 0.41\n",
    "- **MLP (CFNet-ml)**: HR@10 ≈ 0.69, NDCG@10 ≈ 0.42\n",
    "- **CFNet (fusion)**: HR@10 ≈ 0.70, NDCG@10 ≈ 0.43\n",
    "\n",
    "**모델별 특징:**\n",
    "- **DMF**: 두 개의 독립적인 tower로 user와 item을 각각 표현\n",
    "- **MLP**: 단일 네트워크로 user-item 상호작용을 직접 학습\n",
    "- **CFNet**: DMF와 MLP의 앙상블로 최고 성능 달성\n",
    "\n",
    "**성능 향상 메커니즘:**\n",
    "1. **Representation Learning (DMF)**: User/Item의 latent factor를 독립적으로 학습\n",
    "2. **Metric Learning (MLP)**: User-Item 상호작용을 직접 모델링\n",
    "3. **Fusion (CFNet)**: 두 접근법을 결합하여 상호 보완\n",
    "\n",
    "**Note:** \n",
    "- 위 결과는 전체 ML-1M 데이터셋 기준 (6040 users, 3706 items)\n",
    "- 현재 노트북은 샘플 데이터(100 users)로 테스트하므로 성능 차이 발생 가능\n",
    "- 전체 데이터셋으로 학습 시 논문과 유사한 성능 예상\n",
    "- 샘플 데이터에서도 CFNet-pretrain이 가장 높은 성능을 보일 것으로 예상"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
