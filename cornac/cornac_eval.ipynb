{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFNet Model Evaluation with Cornac Framework\n",
    "\n",
    "이 노트북은 Cornac 프레임워크를 사용하여 CFNet 모델들을 베이스라인 모델들과 비교 평가합니다.\n",
    "\n",
    "**평가 지표 (DeepCF 논문과 동일):**\n",
    "- **HR@10** (Hit Ratio@10): Top-10 내 정답 포함 여부\n",
    "- **NDCG@10** (Normalized Discounted Cumulative Gain@10): 순위를 고려한 정확도\n",
    "\n",
    "**비교 모델:**\n",
    "- CFNet-rl (우리 모델 - DMF, representation learning)\n",
    "- CFNet-ml (우리 모델 - MLP, metric learning)\n",
    "- **CFNet-pretrain** (우리 모델 - DMF + MLP fusion with pretrain)\n",
    "- **CFNet-scratch** (우리 모델 - DMF + MLP fusion without pretrain)\n",
    "- NeuMF (Neural Collaborative Filtering)\n",
    "- ItemPop (Item Popularity baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 설정 (Configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 데이터셋 설정\n",
    "# ============================================================\n",
    "DATA_PATH = '../datasets/'\n",
    "DATASET = 'ml-1m'  # 또는 'ml-1m', 'ml-1m-sample1000'\n",
    "\n",
    "# ============================================================\n",
    "# DMF 모델 설정\n",
    "# ============================================================\n",
    "USERLAYERS = [512, 64]\n",
    "ITEMLAYERS = [1024, 64]\n",
    "DMF_LEARNING_RATE = 0.0001\n",
    "\n",
    "# ============================================================\n",
    "# MLP 모델 설정\n",
    "# ============================================================\n",
    "MLP_LAYERS = [512, 256, 128, 64]\n",
    "MLP_LEARNING_RATE = 0.001\n",
    "\n",
    "# ============================================================\n",
    "# CFNet 모델 설정\n",
    "# ============================================================\n",
    "CFNET_LEARNING_RATE = 0.0001\n",
    "PRETRAIN_PATH = '../pretrain/'\n",
    "\n",
    "# ============================================================\n",
    "# 공통 학습 설정\n",
    "# ============================================================\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 256\n",
    "NUM_NEG = 4\n",
    "LEARNER = 'adam'\n",
    "\n",
    "# ============================================================\n",
    "# 평가 설정 (논문과 동일)\n",
    "# ============================================================\n",
    "TEST_SIZE = 0.2  # Train/Test split ratio\n",
    "TOP_K = 10       # HR@10, NDCG@10\n",
    "\n",
    "# ============================================================\n",
    "# 비교할 모델 선택 (True/False)\n",
    "# ============================================================\n",
    "INCLUDE_CFNet_PRETRAIN = True    # CFNet with pretrain\n",
    "INCLUDE_CFNet_SCRATCH = True     # CFNet without pretrain\n",
    "INCLUDE_NCF = True               # NeuMF baseline\n",
    "INCLUDE_MOSTPOP = True           # ItemPop baseline\n",
    "\n",
    "# ============================================================\n",
    "# 기타 설정\n",
    "# ============================================================\n",
    "SEED = 42\n",
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 임포트 (Imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 모든 모듈 임포트 완료\n",
      "Cornac version: 2.3.5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # 상위 디렉토리 추가 (CFNet_pytorch/)\n",
    "\n",
    "import numpy as np\n",
    "import cornac\n",
    "from cornac.eval_methods import RatioSplit\n",
    "from cornac.metrics import HitRatio, NDCG\n",
    "import os\n",
    "\n",
    "# 우리 모델 임포트\n",
    "from cfnet_rl.cornac_dmf_wrapper import CornacDMF\n",
    "from cfnet_ml.cornac_mlp_wrapper import CornacMLP\n",
    "from cfnet.cornac_cfnet_wrapper import CornacCFNet\n",
    "\n",
    "# 공통 유틸리티 임포트\n",
    "from common.data_utils import deepcf_to_uir, load_cornac_data_with_full_space\n",
    "\n",
    "# 베이스라인 모델들\n",
    "from cornac.models import NeuMF, MostPop\n",
    "\n",
    "# 재현성을 위한 시드 설정\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\"✓ 모든 모듈 임포트 완료\")\n",
    "print(f\"Cornac version: {cornac.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 로딩 (Data Loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로딩 중: ml-1m\n",
      "  데이터 경로: ../datasets/\n",
      "\n",
      "✓ 데이터 로딩 완료\n",
      "  Users: 6040, Items: 3706\n",
      "  Train: 994169 interactions\n",
      "  Test: 6040 interactions\n",
      "  샘플 데이터: [('0', '32', 4.0), ('0', '34', 4.0), ('0', '4', 5.0)]\n"
     ]
    }
   ],
   "source": [
    "# 전체 item 공간을 유지하며 데이터 로드 (pretrain 모델과 차원 일치)\n",
    "print(f\"데이터 로딩 중: {DATASET}\")\n",
    "print(f\"  데이터 경로: {DATA_PATH}\")\n",
    "\n",
    "train_data, test_data, num_users, num_items = load_cornac_data_with_full_space(\n",
    "    DATA_PATH, DATASET\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ 데이터 로딩 완료\")\n",
    "print(f\"  Users: {num_users}, Items: {num_items}\")\n",
    "print(f\"  Train: {len(train_data)} interactions\")\n",
    "print(f\"  Test: {len(test_data)} interactions\")\n",
    "print(f\"  샘플 데이터: {train_data[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 평가 방법 설정 (Evaluation Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평가 방법 설정 중...\n",
      "  Global mapping 생성: 6040 users, 3706 items\n",
      "rating_threshold = 0.5\n",
      "exclude_unknowns = False\n",
      "---\n",
      "Training data:\n",
      "Number of users = 6040\n",
      "Number of items = 3704\n",
      "Number of ratings = 994169\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.6\n",
      "---\n",
      "Test data:\n",
      "Number of users = 6040\n",
      "Number of items = 3706\n",
      "Number of ratings = 6040\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 2\n",
      "---\n",
      "Total users = 6040\n",
      "Total items = 3706\n",
      "✓ 평가 방법 설정 완료\n",
      "  Train set: 6040 users, 3704 items\n",
      "  Test set: 6040 users, 3706 items\n",
      "\n",
      "✅ 전체 item 공간(3704)을 사용하여 pretrain 모델과 차원 일치!\n"
     ]
    }
   ],
   "source": [
    "# 전체 item 공간을 반영하기 위한 global mapping 생성\n",
    "from collections import OrderedDict\n",
    "\n",
    "print(\"평가 방법 설정 중...\")\n",
    "\n",
    "# Step 1: train + test 전체에서 global user/item mapping 생성\n",
    "global_uid_map = OrderedDict()\n",
    "global_iid_map = OrderedDict()\n",
    "\n",
    "for uid, iid, rating in train_data + test_data:\n",
    "    global_uid_map.setdefault(uid, len(global_uid_map))\n",
    "    global_iid_map.setdefault(iid, len(global_iid_map))\n",
    "\n",
    "print(f\"  Global mapping 생성: {len(global_uid_map)} users, {len(global_iid_map)} items\")\n",
    "\n",
    "# Step 2: global mapping을 from_splits()에 전달\n",
    "eval_method = cornac.eval_methods.BaseMethod.from_splits(\n",
    "    train_data=train_data,  # raw data (list of tuples)\n",
    "    test_data=test_data,    # raw data (list of tuples)\n",
    "    fmt='UIR',\n",
    "    rating_threshold=0.5,\n",
    "    exclude_unknowns=False,\n",
    "    verbose=VERBOSE,\n",
    "    seed=SEED,\n",
    "    global_uid_map=global_uid_map,  # 전체 user mapping 전달\n",
    "    global_iid_map=global_iid_map   # 전체 item mapping 전달\n",
    ")\n",
    "\n",
    "print(\"✓ 평가 방법 설정 완료\")\n",
    "print(f\"  Train set: {eval_method.train_set.num_users} users, {eval_method.train_set.num_items} items\")\n",
    "print(f\"  Test set: {eval_method.test_set.num_users} users, {eval_method.test_set.num_items} items\")\n",
    "print(f\"\\n✅ 전체 item 공간({eval_method.train_set.num_items})을 사용하여 pretrain 모델과 차원 일치!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 정의 (Model Definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 6개 모델 준비 완료:\n",
      "  - CFNet-rl\n",
      "  - CFNet-ml\n",
      "  - CFNet-pretrain\n",
      "  - CFNet-scratch\n",
      "  - NeuMF\n",
      "  - ItemPop\n"
     ]
    }
   ],
   "source": [
    "# 평가할 모델 리스트\n",
    "models = []\n",
    "\n",
    "# ============================================================\n",
    "# 우리 모델들\n",
    "# ============================================================\n",
    "\n",
    "# CFNet-rl (DMF) 모델 (representation learning)\n",
    "dmf = CornacDMF(\n",
    "    name=\"CFNet-rl\",\n",
    "    userlayers=USERLAYERS,\n",
    "    itemlayers=ITEMLAYERS,\n",
    "    num_epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_neg=NUM_NEG,\n",
    "    learning_rate=DMF_LEARNING_RATE,\n",
    "    learner=LEARNER,\n",
    "    use_gpu=True,\n",
    "    seed=SEED,\n",
    "    verbose=VERBOSE\n",
    ")\n",
    "models.append(dmf)\n",
    "\n",
    "# CFNet-ml (MLP) 모델 (metric learning)\n",
    "mlp = CornacMLP(\n",
    "    name=\"CFNet-ml\",\n",
    "    layers=MLP_LAYERS,\n",
    "    num_epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_neg=NUM_NEG,\n",
    "    learning_rate=MLP_LEARNING_RATE,\n",
    "    learner=LEARNER,\n",
    "    use_gpu=True,\n",
    "    seed=SEED,\n",
    "    verbose=VERBOSE\n",
    ")\n",
    "models.append(mlp)\n",
    "\n",
    "# ============================================================\n",
    "# CFNet Fusion 모델들\n",
    "# ============================================================\n",
    "\n",
    "if INCLUDE_CFNet_PRETRAIN:\n",
    "    # Pretrain 모델 경로 설정 (데이터셋 prefix 사용)\n",
    "    dmf_pretrain_path = os.path.join(PRETRAIN_PATH, f'{DATASET}-rl.pth')\n",
    "    mlp_pretrain_path = os.path.join(PRETRAIN_PATH, f'{DATASET}-ml.pth')\n",
    "    \n",
    "    # 파일 존재 확인\n",
    "    if os.path.exists(dmf_pretrain_path) and os.path.exists(mlp_pretrain_path):\n",
    "        cfnet_pretrain = CornacCFNet(\n",
    "            name=\"CFNet-pretrain\",\n",
    "            userlayers=USERLAYERS,\n",
    "            itemlayers=ITEMLAYERS,\n",
    "            layers=MLP_LAYERS,\n",
    "            dmf_pretrain_path=dmf_pretrain_path,\n",
    "            mlp_pretrain_path=mlp_pretrain_path,\n",
    "            num_epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            num_neg=NUM_NEG,\n",
    "            learning_rate=CFNET_LEARNING_RATE,\n",
    "            learner=LEARNER,\n",
    "            use_gpu=True,\n",
    "            seed=SEED,\n",
    "            verbose=VERBOSE\n",
    "        )\n",
    "        models.append(cfnet_pretrain)\n",
    "    else:\n",
    "        print(f\"⚠️  Pretrain 파일을 찾을 수 없습니다. CFNet-pretrain 모델을 건너뜁니다.\")\n",
    "        print(f\"   DMF: {dmf_pretrain_path} (존재: {os.path.exists(dmf_pretrain_path)})\")\n",
    "        print(f\"   MLP: {mlp_pretrain_path} (존재: {os.path.exists(mlp_pretrain_path)})\")\n",
    "        print(f\"\\n   Pretrain 모델을 생성하려면:\")\n",
    "        print(f\"   1. cfnet_rl/dmf_train.ipynb 실행 → {DATASET}-rl.pth 생성\")\n",
    "        print(f\"   2. cfnet_ml/mlp_train.ipynb 실행 → {DATASET}-ml.pth 생성\")\n",
    "\n",
    "if INCLUDE_CFNet_SCRATCH:\n",
    "    cfnet_scratch = CornacCFNet(\n",
    "        name=\"CFNet-scratch\",\n",
    "        userlayers=USERLAYERS,\n",
    "        itemlayers=ITEMLAYERS,\n",
    "        layers=MLP_LAYERS,\n",
    "        dmf_pretrain_path=None,  # No pretrain\n",
    "        mlp_pretrain_path=None,  # No pretrain\n",
    "        num_epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_neg=NUM_NEG,\n",
    "        learning_rate=CFNET_LEARNING_RATE,\n",
    "        learner=LEARNER,\n",
    "        use_gpu=True,\n",
    "        seed=SEED,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    models.append(cfnet_scratch)\n",
    "\n",
    "# ============================================================\n",
    "# 베이스라인 모델들\n",
    "# ============================================================\n",
    "\n",
    "if INCLUDE_NCF:\n",
    "    neumf = NeuMF(\n",
    "        name=\"NeuMF\",\n",
    "        num_factors=8,           # GMF embedding size\n",
    "        layers=[64, 32, 16, 8],  # MLP layers\n",
    "        act_fn=\"relu\",\n",
    "        learner=LEARNER,\n",
    "        backend=\"pytorch\",       # PyTorch 백엔드 사용 (TensorFlow 대신)\n",
    "        num_epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        lr=0.001,                # NeuMF는 'lr' 파라미터 사용\n",
    "        num_neg=NUM_NEG,\n",
    "        verbose=VERBOSE,\n",
    "        seed=SEED\n",
    "    )\n",
    "    models.append(neumf)\n",
    "\n",
    "if INCLUDE_MOSTPOP:\n",
    "    mostpop = MostPop(\n",
    "        name=\"ItemPop\"  # 논문의 ItemPop과 대응\n",
    "    )\n",
    "    models.append(mostpop)\n",
    "\n",
    "print(f\"✓ {len(models)}개 모델 준비 완료:\")\n",
    "for model in models:\n",
    "    print(f\"  - {model.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 평가 실행 (Run Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "평가 시작\n",
      "======================================================================\n",
      "\n",
      "평가 지표: HR@10, NDCG@10\n",
      "\n",
      "[CFNet-rl] Training started!\n",
      "  [DMF] Epoch  0: Loss = 0.2746\n",
      "  [DMF] Epoch  5: Loss = 0.2321\n",
      "  [DMF] Epoch 10: Loss = 0.2240\n",
      "  [DMF] Epoch 15: Loss = 0.2197\n",
      "\n",
      "[CFNet-rl] Evaluation started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking: 100%|██████████| 6040/6040 [01:42<00:00, 58.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CFNet-ml] Training started!\n",
      "  [MLP] Epoch  0: Loss = 0.2761\n",
      "  [MLP] Epoch  5: Loss = 0.2336\n",
      "  [MLP] Epoch 10: Loss = 0.2210\n",
      "  [MLP] Epoch 15: Loss = 0.2119\n",
      "\n",
      "[CFNet-ml] Evaluation started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking: 100%|██████████| 6040/6040 [00:29<00:00, 202.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CFNet-pretrain] Training started!\n",
      "\n",
      "[CFNet-pretrain] Using pretrained model dimensions:\n",
      "  - Pretrained num_items: 3706\n",
      "  - Train set num_items: 3704\n",
      "  ⚠️  Dimension mismatch detected - using pretrained dimension (3706)\n",
      "\n",
      "[CFNet-pretrain] Using pretrained weights:\n",
      "  - DMF: ../pretrain/ml-1m-rl.pth\n",
      "  - MLP: ../pretrain/ml-1m-ml.pth\n",
      "\n",
      "[CFNet-pretrain] Training started!\n",
      "  [CFNet-pretrain] Epoch  0: Loss = 0.2508\n",
      "  [CFNet-pretrain] Epoch  5: Loss = 0.2124\n",
      "  [CFNet-pretrain] Epoch 10: Loss = 0.1999\n",
      "  [CFNet-pretrain] Epoch 15: Loss = 0.1910\n",
      "\n",
      "[CFNet-pretrain] Evaluation started!\n",
      "\n",
      "[CFNet-pretrain] Evaluation started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking: 100%|██████████| 6040/6040 [01:56<00:00, 51.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CFNet-scratch] Training started!\n",
      "\n",
      "[CFNet-scratch] Training from scratch (no pretrain)\n",
      "\n",
      "[CFNet-scratch] Training started!\n",
      "  [CFNet-scratch] Epoch  0: Loss = 0.2645\n",
      "  [CFNet-scratch] Epoch  5: Loss = 0.2081\n",
      "  [CFNet-scratch] Epoch 10: Loss = 0.1851\n",
      "  [CFNet-scratch] Epoch 15: Loss = 0.1665\n",
      "\n",
      "[CFNet-scratch] Evaluation started!\n",
      "\n",
      "[CFNet-scratch] Evaluation started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking: 100%|██████████| 6040/6040 [01:09<00:00, 86.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeuMF] Training started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [08:01<00:00, 24.10s/it, loss=0.223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeuMF] Evaluation started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking: 100%|██████████| 6040/6040 [00:05<00:00, 1190.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ItemPop] Training started!\n",
      "\n",
      "[ItemPop] Evaluation started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking: 100%|██████████| 6040/6040 [00:00<00:00, 9868.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "               | HitRatio@10 | NDCG@10 | Train (s) | Test (s)\n",
      "-------------- + ----------- + ------- + --------- + --------\n",
      "CFNet-rl       |      0.0841 |  0.0413 | 1802.6938 | 102.6578\n",
      "CFNet-ml       |      0.0844 |  0.0412 | 1268.1842 |  29.8065\n",
      "CFNet-pretrain |      0.0960 |  0.0476 | 2403.6395 | 116.4118\n",
      "CFNet-scratch  |      0.0884 |  0.0429 | 2444.5320 |  69.7182\n",
      "NeuMF          |      0.0767 |  0.0382 |  482.0039 |   5.0740\n",
      "ItemPop        |      0.0414 |  0.0204 |    0.0035 |   0.6131\n",
      "\n",
      "\n",
      "======================================================================\n",
      "평가 완료\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 논문과 동일한 평가 지표\n",
    "metrics = [\n",
    "    HitRatio(k=TOP_K),  # HR@10\n",
    "    NDCG(k=TOP_K),      # NDCG@10\n",
    "]\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"평가 시작\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "print(f\"평가 지표: HR@{TOP_K}, NDCG@{TOP_K}\")\n",
    "\n",
    "# Cornac Experiment 실행\n",
    "experiment = cornac.Experiment(\n",
    "    eval_method=eval_method,\n",
    "    models=models,\n",
    "    metrics=metrics,\n",
    "    user_based=True,\n",
    "    save_dir=None\n",
    ")\n",
    "\n",
    "experiment.run()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"평가 완료\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 결과 분석 (Result Analysis)\n",
    "\n",
    "### 평가 지표 (DeepCF 논문과 동일)\n",
    "\n",
    "위의 결과 테이블에서:\n",
    "- **HR@10 (Hit Ratio@10)**: Top-10 추천 리스트에 관련 아이템이 포함되면 1, 아니면 0. 전체 평균값으로 표시.\n",
    "- **NDCG@10**: 순위를 고려한 정확도. 관련 아이템이 상위에 있을수록 높은 점수.\n",
    "  - 계산: $NDCG@K = \\frac{1}{|U|} \\sum_{u} \\frac{\\log 2}{\\log(rank_u + 1)}$\n",
    "- **Train (s)**: 모델 학습 시간 (초)\n",
    "- **Test (s)**: 모델 평가 시간 (초)\n",
    "\n",
    "### 예상 결과 형식\n",
    "\n",
    "```\n",
    "TEST:\n",
    "                 | HitRatio@10 | NDCG@10 | Train (s) | Test (s)\n",
    "---------------- + ----------- + ------- + --------- + --------\n",
    "CFNet-rl         |      0.4301 |  0.2096 |   36.5441 |   0.5954\n",
    "CFNet-ml         |      0.4420 |  0.2150 |   32.1234 |   0.5123\n",
    "CFNet-pretrain   |      0.4580 |  0.2250 |   35.2345 |   0.6012  ⭐ 최고 성능 예상\n",
    "CFNet-scratch    |      0.4380 |  0.2100 |   35.8765 |   0.6023\n",
    "NeuMF            |      0.3850 |  0.1865 |   12.1513 |   0.2225\n",
    "ItemPop          |      0.3920 |  0.2044 |    0.0009 |   0.2071\n",
    "```\n",
    "\n",
    "### 성능 비교 가이드\n",
    "\n",
    "**기본 모델 (DMF vs MLP):**\n",
    "- **DMF (CFNet-rl)**: Element-wise product 기반 representation learning\n",
    "  - User/Item tower를 각각 학습 후 곱셈으로 결합\n",
    "  - 학습률: 0.0001 (낮은 학습률)\n",
    "  - 구조: User [512, 64], Item [1024, 64]\n",
    "  \n",
    "- **MLP (CFNet-ml)**: Concatenation 기반 metric learning\n",
    "  - User/Item embedding을 연결 후 MLP로 학습\n",
    "  - 학습률: 0.001 (높은 학습률)\n",
    "  - 구조: [512, 256, 128, 64]\n",
    "  \n",
    "- **논문의 주장**: MLP가 DMF보다 약간 더 높은 성능 (concatenation이 더 많은 정보 보존)\n",
    "\n",
    "**CFNet Fusion 모델:**\n",
    "- **CFNet-pretrain**: DMF와 MLP를 먼저 개별 학습 후 가중치를 로드하여 fusion\n",
    "  - ⭐ **최고 성능 예상**: Pretrain을 통해 각 모델의 장점을 효과적으로 결합\n",
    "  - DMF의 element-wise product + MLP의 concatenation을 모두 활용\n",
    "  - Pretrain된 가중치로 시작하므로 안정적인 학습\n",
    "  \n",
    "- **CFNet-scratch**: 랜덤 초기화로 DMF와 MLP를 동시에 학습\n",
    "  - CFNet-pretrain보다 낮은 성능 예상\n",
    "  - 두 개의 복잡한 모델을 동시에 학습하는 어려움\n",
    "  - 하지만 단일 모델(DMF, MLP)보다는 높은 성능 기대\n",
    "\n",
    "**베이스라인과의 비교:**\n",
    "- **HR@10**: Top-10 추천 정확도. 베이스라인 대비 높을수록 우수\n",
    "- **NDCG@10**: 순위 품질. 높을수록 관련 아이템이 상위에 위치\n",
    "- **학습 시간**: Deep learning 모델 특성상 길지만, 성능 향상이 trade-off\n",
    "- **평가 시간**: 실시간 추천 시스템에서 중요한 지표\n",
    "\n",
    "### DeepCF 논문 결과 참고 (ML-1M 전체 데이터)\n",
    "\n",
    "논문에서 보고된 성능:\n",
    "- **DMF (CFNet-rl)**: HR@10 ≈ 0.68, NDCG@10 ≈ 0.41\n",
    "- **MLP (CFNet-ml)**: HR@10 ≈ 0.69, NDCG@10 ≈ 0.42\n",
    "- **CFNet (fusion)**: HR@10 ≈ 0.70, NDCG@10 ≈ 0.43\n",
    "\n",
    "**모델별 특징:**\n",
    "- **DMF**: 두 개의 독립적인 tower로 user와 item을 각각 표현\n",
    "- **MLP**: 단일 네트워크로 user-item 상호작용을 직접 학습\n",
    "- **CFNet**: DMF와 MLP의 앙상블로 최고 성능 달성\n",
    "\n",
    "**성능 향상 메커니즘:**\n",
    "1. **Representation Learning (DMF)**: User/Item의 latent factor를 독립적으로 학습\n",
    "2. **Metric Learning (MLP)**: User-Item 상호작용을 직접 모델링\n",
    "3. **Fusion (CFNet)**: 두 접근법을 결합하여 상호 보완\n",
    "\n",
    "**Note:** \n",
    "- 위 결과는 전체 ML-1M 데이터셋 기준 (6040 users, 3706 items)\n",
    "- 현재 노트북은 샘플 데이터(100 users)로 테스트하므로 성능 차이 발생 가능\n",
    "- 전체 데이터셋으로 학습 시 논문과 유사한 성능 예상\n",
    "- 샘플 데이터에서도 CFNet-pretrain이 가장 높은 성능을 보일 것으로 예상"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
