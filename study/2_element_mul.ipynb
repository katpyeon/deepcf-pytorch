{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0184f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "slrh13wxpxc",
   "source": "# 내적 vs 요소별 곱셈 비교\n\n추천 시스템에서 사용자-항목 매칭 점수를 계산하는 두 가지 방식을 비교합니다.\n\n## 핵심 차이점\n\n### 전통적 행렬분해 (Matrix Factorization)\n- 사용자 벡터와 항목 벡터의 **내적(Dot Product)** 사용\n- 결과: **스칼라** (단일 점수)\n- 모든 차원의 정보를 합쳐서 하나의 값으로 압축\n\n### CFNet (Collaborative Filtering Network)\n- 사용자 벡터와 항목 벡터의 **요소별 곱셈(Element-wise Product)** 사용\n- 결과: **벡터** (차원별 상호작용 보존)\n- 학습된 가중치로 각 차원의 중요도를 다르게 반영\n\n## 왜 이것이 중요한가?\n\n내적은 모든 차원을 동등하게 취급하지만, CFNet은 **어떤 차원이 더 중요한지 학습**할 수 있습니다!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5805211",
   "metadata": {},
   "outputs": [],
   "source": "# 가상의 사용자 잠재 벡터 (User Latent Factor: Pu)\n# 1차원: 액션 선호 (높음) / 2차원: 코미디 선호 (중간) / 3차원: 고전 선호 (낮음)\nPu = np.array([0.9, 0.5, 0.1]) \n\n# 가상의 항목 잠재 벡터 (Item Latent Factor: Qi)\n# 1차원: 액션 영화 (강함) / 2차원: 코미디 영화 (약함) / 3차원: 고전 영화 (강함)\nQi = np.array([0.8, 0.2, 0.9])\n\nprint(\"사용자 잠재 벡터 (Pu):\", Pu)\nprint(\"  -> 액션 선호 높음, 코미디 중간, 고전 낮음\")\nprint()\nprint(\"항목 잠재 벡터 (Qi):\", Qi)\nprint(\"  -> 액션 영화 강함, 코미디 약함, 고전 강함\")"
  },
  {
   "cell_type": "markdown",
   "id": "16vzlwbr2fv",
   "source": "## 2. 전통적 방식: 내적 (Dot Product)\n\n**계산 방법:** 각 차원의 곱을 모두 더해서 **하나의 스칼라 값**으로 압축\n\n**공식:** `score = Pu · Qi = Pu[0]*Qi[0] + Pu[1]*Qi[1] + Pu[2]*Qi[2]`\n\n**특징:**\n- 모든 차원을 동등하게 취급\n- 결과가 단일 숫자 (스칼라)\n- 차원별 기여도를 구분할 수 없음",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "xogn4wje2cs",
   "source": "## 1. 잠재 벡터 정의\n\n한 명의 사용자와 한 개의 영화에 대한 잠재 벡터를 정의합니다.\n\n**잠재 요인 3개:**\n- 1차원: 액션 장르 선호도/특성\n- 2차원: 코미디 장르 선호도/특성  \n- 3차원: 고전 장르 선호도/특성\n\n각 값은 0~1 사이로, 높을수록 해당 장르에 대한 선호/특성이 강함을 의미합니다.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc059bc3",
   "metadata": {},
   "outputs": [],
   "source": "# 내적 계산: 각 차원의 곱을 합산\ndot_product_score = np.dot(Pu, Qi)\n\nprint(\"=\" * 50)\nprint(\"내적 (Dot Product) 계산 과정\")\nprint(\"=\" * 50)\n\n# 각 차원별 계산 상세히 보여주기\ndim_products = Pu * Qi\nprint(f\"1차원 (액션):   {Pu[0]:.1f} x {Qi[0]:.1f} = {dim_products[0]:.2f}\")\nprint(f\"2차원 (코미디): {Pu[1]:.1f} x {Qi[1]:.1f} = {dim_products[1]:.2f}\")\nprint(f\"3차원 (고전):   {Pu[2]:.1f} x {Qi[2]:.1f} = {dim_products[2]:.2f}\")\nprint(\"-\" * 50)\nprint(f\"합산 (Sum):     {dim_products[0]:.2f} + {dim_products[1]:.2f} + {dim_products[2]:.2f} = {dot_product_score:.4f}\")\nprint(\"=\" * 50)\nprint(f\"\\n최종 매칭 점수 (스칼라): {dot_product_score:.4f}\")\nprint(\"\\n-> 모든 차원이 하나의 값으로 합쳐져서 개별 기여도를 알 수 없음!\")"
  },
  {
   "cell_type": "markdown",
   "id": "rrpx95ciypl",
   "source": "## 3. CFNet 방식: 요소별 곱셈 (Element-wise Product)\n\n**계산 방법:** 각 차원의 곱을 **벡터로 유지** (합산하지 않음!)\n\n**공식:** `vector = Pu ⊙ Qi = [Pu[0]*Qi[0], Pu[1]*Qi[1], Pu[2]*Qi[2]]`\n\n**특징:**\n- 각 차원의 상호작용을 별도로 보존\n- 결과가 벡터 (차원별 정보 유지)\n- 이후 학습된 가중치로 중요도를 다르게 반영 가능\n\n**핵심 차이:** 내적은 바로 합산하지만, 요소별 곱셈은 **나중에** 가중치를 적용해서 합산!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078fe292",
   "metadata": {},
   "outputs": [],
   "source": "# 요소별 곱셈: 각 차원의 상호작용을 벡터로 보존\ninteraction_vector = Pu * Qi\n\nprint(\"=\" * 50)\nprint(\"요소별 곱셈 (Element-wise Product) 계산 과정\")\nprint(\"=\" * 50)\n\n# 각 차원별 계산 상세히 보여주기\nprint(f\"1차원 (액션):   {Pu[0]:.1f} x {Qi[0]:.1f} = {interaction_vector[0]:.2f}\")\nprint(f\"2차원 (코미디): {Pu[1]:.1f} x {Qi[1]:.1f} = {interaction_vector[1]:.2f}\")\nprint(f\"3차원 (고전):   {Pu[2]:.1f} x {Qi[2]:.1f} = {interaction_vector[2]:.2f}\")\nprint(\"=\" * 50)\nprint(f\"\\n예측 벡터 (Vector): {interaction_vector}\")\nprint(\"\\n-> 각 차원의 정보가 벡터로 보존됨!\")\nprint(\"-> 이제 학습된 가중치로 각 차원의 중요도를 다르게 반영 가능\")"
  },
  {
   "cell_type": "markdown",
   "id": "b4bel1peqh",
   "source": "## 4. 학습된 가중치로 최종 점수 계산\n\nCFNet은 예측 벡터에 **학습된 가중치 W_out**를 적용하여 최종 점수를 계산합니다.\n\n**공식:** `final_score = W_out · interaction_vector`\n\n**가중치의 의미:**\n- W_out[0] (액션 차원의 중요도)\n- W_out[1] (코미디 차원의 중요도)\n- W_out[2] (고전 차원의 중요도)\n\n**학습 과정에서:**\n- 이 가중치들은 데이터로부터 자동으로 학습됨\n- 예측 정확도가 높아지도록 최적화됨\n- 어떤 장르가 평점에 더 중요한지 모델이 스스로 발견!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de39a58",
   "metadata": {},
   "outputs": [],
   "source": "# 가중치 벡터 (학습을 통해 얻어진 각 차원의 중요도)\n# 이 예제에서는 액션(0.5)과 고전(0.4)이 중요하고, 코미디(0.1)는 덜 중요하다고 가정\nW_out = np.array([0.5, 0.1, 0.4])\n\n# 가중치와 예측 벡터의 내적으로 최종 점수 계산\nfinal_matching_score_cfnet = np.dot(W_out, interaction_vector)\n\nprint(\"=\" * 50)\nprint(\"CFNet 최종 점수 계산 (가중치 적용)\")\nprint(\"=\" * 50)\n\nprint(f\"\\n가중치 벡터 (W_out): {W_out}\")\nprint(\"  -> 액션: {:.1f} (중요), 코미디: {:.1f} (덜 중요), 고전: {:.1f} (중요)\".format(W_out[0], W_out[1], W_out[2]))\n\nprint(f\"\\n예측 벡터: {interaction_vector}\")\n\nprint(\"\\n가중합 계산:\")\nprint(f\"  액션 기여:   {W_out[0]:.1f} x {interaction_vector[0]:.2f} = {W_out[0] * interaction_vector[0]:.4f}\")\nprint(f\"  코미디 기여: {W_out[1]:.1f} x {interaction_vector[1]:.2f} = {W_out[1] * interaction_vector[1]:.4f}\")\nprint(f\"  고전 기여:   {W_out[2]:.1f} x {interaction_vector[2]:.2f} = {W_out[2] * interaction_vector[2]:.4f}\")\nprint(\"-\" * 50)\nprint(f\"  합산: {W_out[0] * interaction_vector[0]:.4f} + {W_out[1] * interaction_vector[1]:.4f} + {W_out[2] * interaction_vector[2]:.4f} = {final_matching_score_cfnet:.4f}\")\n\nprint(\"=\" * 50)\nprint(f\"\\n최종 매칭 점수 (CFNet): {final_matching_score_cfnet:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "blqq3phogeo",
   "source": "## 5. 두 방식 비교\n\n내적 방식과 CFNet 방식의 최종 점수를 비교해봅시다.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "xld8ihz85ur",
   "source": "print(\"\\n\" + \"=\" * 60)\nprint(\"최종 비교: 내적 vs CFNet\")\nprint(\"=\" * 60)\n\nprint(f\"\\n내적 방식 점수:     {dot_product_score:.4f}\")\nprint(f\"CFNet 방식 점수:    {final_matching_score_cfnet:.4f}\")\nprint(f\"점수 차이:          {abs(dot_product_score - final_matching_score_cfnet):.4f}\")\n\nprint(\"\\n\" + \"-\" * 60)\nprint(\"왜 결과가 다를까?\")\nprint(\"-\" * 60)\n\nprint(\"\\n내적 방식:\")\nprint(\"  - 모든 차원을 동등하게 (1:1:1 비율로) 합산\")\nprint(\"  - 암묵적 가중치: [1.0, 1.0, 1.0]\")\nprint(f\"  - 계산: 1.0*{interaction_vector[0]:.2f} + 1.0*{interaction_vector[1]:.2f} + 1.0*{interaction_vector[2]:.2f} = {dot_product_score:.4f}\")\n\nprint(\"\\nCFNet 방식:\")\nprint(\"  - 학습된 가중치로 차원별 중요도를 다르게 반영\")\nprint(f\"  - 학습된 가중치: {W_out}\")\nprint(f\"  - 계산: {W_out[0]:.1f}*{interaction_vector[0]:.2f} + {W_out[1]:.1f}*{interaction_vector[1]:.2f} + {W_out[2]:.1f}*{interaction_vector[2]:.2f} = {final_matching_score_cfnet:.4f}\")\n\nprint(\"\\n결론:\")\nprint(\"  CFNet은 데이터를 통해 어떤 장르가 더 중요한지 학습하므로\")\nprint(\"  더 정확한 예측이 가능합니다!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "87f4392c",
   "metadata": {},
   "outputs": [],
   "source": "## 핵심 요약\n\n### 내적 방식의 한계\n1. **고정된 가중치**: 모든 차원을 동등하게 취급 (암묵적으로 가중치 = 1)\n2. **표현력 부족**: 어떤 장르가 더 중요한지 구분 불가\n3. **정보 손실**: 차원별 기여도를 합산 과정에서 잃어버림\n\n### CFNet 방식의 장점\n1. **학습 가능한 가중치**: 데이터로부터 각 차원의 중요도를 자동으로 학습\n2. **높은 표현력**: 장르별로 다른 중요도 반영 가능\n3. **정보 보존**: 요소별 곱셈으로 차원별 상호작용을 벡터로 유지\n\n### 실제 적용\n- **전통적 행렬분해**: 간단하고 빠르지만 표현력 제한\n- **CFNet (딥러닝 기반)**: 더 복잡하지만 더 정확한 예측 가능\n- **실무에서**: 데이터가 많고 정확도가 중요하면 CFNet 방식 선호\n\n### 수식 정리\n```\n전통적 방식: score = Pu · Qi = Σ(Pu[i] * Qi[i])\nCFNet 방식:  score = W_out · (Pu ⊙ Qi) = Σ(W_out[i] * Pu[i] * Qi[i])\n```\n\n차이는 **학습 가능한 가중치 W_out**의 유무!"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}